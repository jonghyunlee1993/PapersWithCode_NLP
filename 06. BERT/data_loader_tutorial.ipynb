{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "25e71722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "fpath='data/tokenizer_model'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(fpath,\n",
    "                                              strip_accents=False,\n",
    "                                              lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d660f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTLangaugeModelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_seq_len=128, masking_ratio=0.15, NSP_ratio=0.5):\n",
    "        super(BERTLangaugeModelDataset, self).__init__()\n",
    "\n",
    "        self.data          = data        \n",
    "        self.tokenizer     = tokenizer\n",
    "        self.vocab         = tokenizer.vocab\n",
    "        self.max_seq_len   = max_seq_len\n",
    "        self.masking_ratio = masking_ratio\n",
    "        self.NSP_ratio     = NSP_ratio\n",
    "        \n",
    "        self.cls_token_id  = self.tokenizer.cls_token_id\n",
    "        self.sep_token_id  = self.tokenizer.sep_token_id\n",
    "        self.pad_token_id  = self.tokenizer.pad_token_id\n",
    "        self.mask_token_id = self.tokenizer.mask_token_id\n",
    "        \n",
    "    def __getitem__(self, sent_1_idx):       \n",
    "        sent_1 = self.tokenizer.encode(self.data[sent_1_idx])[1:-1]\n",
    "        sent_2_idx = sent_1_idx + 1\n",
    "        \n",
    "        # NSP\n",
    "        if torch.rand(1) >= self.NSP_ratio:\n",
    "            sent_2 = self.tokenizer.encode(self.data[sent_1_idx + 1])[1:-1]\n",
    "            is_next = torch.tensor(1)\n",
    "        else:\n",
    "            while sent_2_idx == sent_1_idx + 1:\n",
    "                sent_2_idx = torch.randint(0, len(self.data), (1,))\n",
    "            is_next = torch.tensor(0)\n",
    "\n",
    "        sent_2 = self.tokenizer.encode(self.data[sent_2_idx])[1:-1]\n",
    "        \n",
    "        # if length of (sent 1 + sent 2) longer than threshold\n",
    "        # CLS, SEP 1 and 2\n",
    "        if len(sent_1) + len(sent_2) >= self.max_seq_len - 3:\n",
    "            sent_2 = sent_2[:self.max_seq_len - 3 - len(sent_1)]\n",
    "        \n",
    "        pad_length = self.max_seq_len - 3 - len(sent_1) - len(sent_2)\n",
    "        target = torch.tensor([self.cls_token_id] + sent_1 + [self.sep_token_id] + sent_2 + [self.sep_token_id] + [self.pad_token_id] * pad_length).long().contiguous()        \n",
    "\n",
    "        sent_embedding = torch.zeros(target.size(0))\n",
    "        sent_embedding[(len(sent_1) + 2):] = 1\n",
    "        \n",
    "        # MLM\n",
    "        train = torch.cat([\n",
    "            torch.tensor([self.cls_token_id]), \n",
    "            self.masking(sent_1),\n",
    "            torch.tensor([self.sep_token_id]),\n",
    "            self.masking(sent_2),\n",
    "            torch.tensor([self.sep_token_id]),\n",
    "            torch.tensor([self.pad_token_id] * pad_length)\n",
    "        ]).long().contiguous()\n",
    "        \n",
    "        return train, target, sent_embedding, is_next\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.data:\n",
    "            yield x\n",
    "            \n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.tokenizer.batch_decode(x)\n",
    "    \n",
    "    \n",
    "    def masking(self, x):\n",
    "        x = torch.tensor(x).long().contiguous()\n",
    "        masking_idx   = torch.randperm(x.size()[0])[:round(x.size()[0] * self.masking_ratio) + 1]       \n",
    "        masking_label = torch.zeros(x.size()[0])\n",
    "        masking_label[masking_idx] = 1\n",
    "        x = x.masked_fill(masking_label.bool(), self.mask_token_id)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "242a1232",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/petitions.txt\", 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "    \n",
    "proced_data = [line.replace(\"\\n\", \"\") for line in data]\n",
    "# proced_data = []\n",
    "# for line in data:\n",
    "#     proced_data.append(line.replace(\"\\n\", \"\").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b230d344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['êµ­ë¯¼ê³¼ ì†Œí†µí•˜ì‹œê³  ììœ ë¡­ê³  í–‰ë³µí•œ ë‚˜ë¼ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ í˜ì“°ê³  ê³„ì‹  ëŒ€í†µë ¹ê»˜ ì¡´ê²½ê³¼ ì°¬ì‚¬ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤.',\n",
       " 'ê¸°í•´ë…„ ìƒˆí•´ ë³µ ë§ì´ ë°›ìœ¼ì‹­ì‹œì˜¤.',\n",
       " 'ì €ëŠ” ê²½ë¶ ìš¸ì§„êµ° ë¶ë©´ ë¶€êµ¬ê²€ì„±ë¡œ 12ë²ˆì§€ì— ì‚´ê³  ìˆëŠ” ë¶ë©´ë°œì „í˜‘ì˜íšŒì¥ ì´í¬êµ­ì´ë¼ê³  í•©ë‹ˆë‹¤.',\n",
       " 'ì €ëŠ” 8ê¸°ì˜ ì›ì „ì´ ê°€ë™â€¤ê±´ì„¤ë˜ê³  ìˆëŠ” ì´ê³³ ë¶ë©´ì— íƒœì–´ë‚˜ 68ë…„ì§¸ ê±°ì£¼í•˜ê³  ìˆëŠ” ì›ì „ì§€ì—­ ì£¼ë¯¼ì…ë‹ˆë‹¤.',\n",
       " 'ê°„ì ˆí•œ ë§ˆìŒì„ ë‹´ì•„ ëŒ€í†µë ¹ê»˜ ë‹¤ìŒê³¼ ê°™ì´ í˜¸ì†Œ ë“œë¦½ë‹ˆë‹¤.',\n",
       " 'â€˜ìš¸ì§„êµ°ë¯¼ê³¼ ì•½ì†í•œ ì‹ í•œìš¸ 3,4í˜¸ê¸° ì›ì „ê±´ì„¤ì„ ì¬ê°œí•´ ì£¼ì‹­ì‹œì˜¤.â€™ ì—¬íƒœê» ë‹¨ í•œ ë²ˆë„ ì›ì „ ê±´ì„¤ì„ ì›í•œ ì  ì—†ëŠ” ì œê°€ ì‹ í•œìš¸ 3,4í˜¸ê¸° ì›ì „ ê±´ì„¤ì„ ì²­í•˜ëŠ” ê¹Œë‹­ì„ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.',\n",
       " 'ê²½ìƒë¶ë„ ë™í•´ì•ˆ ìµœë¶ë‹¨ ìš¸ì§„êµ°ì€ ì˜ˆë¶€í„° ì‚°ê³¼ ë°”ë‹¤, ê³„ê³¡ì˜ ìš¸ì°½í•¨ì´ ë³´ë°°ì²˜ëŸ¼ ì•„ë¦„ë‹µë‹¤í•˜ì—¬ â€œìš¸ì§„(è”šç)â€ì´ë¼ëŠ” ì§€ëª…ì„ ê°„ì§í•˜ê²Œ ëœ ê³³ì…ë‹ˆë‹¤.',\n",
       " 'ì´ëŸ¬í•œ ê³³ì— 1981ë…„ ì›ì „ì‚¬ì—…ì˜ ì‹œì‘ìœ¼ë¡œ ìš¸ì§„êµ°ì— ë¶ë©´(6ê¸°), ì‚°í¬ì§€êµ¬(6ê¸°), ì§ì‚°ì§€êµ¬(6ê¸°)ê°€ ì›ì „ ì˜ˆì •ì§€ì—­ìœ¼ë¡œ ì§€ì •ë˜ë©´ì„œ, ë¨¼ì € ë¶ë©´ ë¶€êµ¬ë¦¬ ì§€ì—­ì— ì›ì „ 6ê¸°ê°€ ê±´ì„¤ë˜ì—ˆìŠµë‹ˆë‹¤.',\n",
       " 'í•´ì•ˆì„ ì´ ì˜ë ¤ë‚˜ê°€ê³  ë§ˆì„ í•œë³µíŒì— ê³ ì•• ì†¡ì „íƒ‘ì´ ë“¤ì–´ì„°ìŠµë‹ˆë‹¤.',\n",
       " 'ì–´ì¥ì´ íŒŒê´´ë˜ê³  ì§€ì—­ íŠ¹ì‚°í’ˆì— ë°©ì‚¬ëŠ¥ ê¼¬ë¦¬í‘œê°€ ë¶™ì—ˆìŠµë‹ˆë‹¤.']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proced_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "22fb7dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'êµ­ë¯¼',\n",
       " '##ê³¼',\n",
       " 'ì†Œí†µ',\n",
       " '##í•˜',\n",
       " '##ì‹œê³ ',\n",
       " 'ììœ ',\n",
       " '##ë¡­',\n",
       " '##ê³ ',\n",
       " 'í–‰ë³µ',\n",
       " '##í•œ',\n",
       " 'ë‚˜ë¼',\n",
       " '##ë¥¼',\n",
       " 'ë§Œë“¤',\n",
       " '##ê¸°',\n",
       " 'ìœ„í•´',\n",
       " 'í˜ì“°',\n",
       " '##ê³ ',\n",
       " 'ê³„ì‹ ',\n",
       " 'ëŒ€í†µë ¹',\n",
       " '##ê»˜',\n",
       " 'ì¡´ê²½',\n",
       " '##ê³¼',\n",
       " 'ì°¬ì‚¬',\n",
       " '##ë¥¼',\n",
       " 'ì˜¬ë¦½ë‹ˆë‹¤',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer.encode(proced_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c2fdcbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] êµ­ë¯¼ê³¼ ì†Œí†µí•˜ì‹œê³  ììœ ë¡­ê³  í–‰ë³µí•œ ë‚˜ë¼ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ í˜ì“°ê³  ê³„ì‹  ëŒ€í†µë ¹ê»˜ ì¡´ê²½ê³¼ ì°¬ì‚¬ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤. [SEP]'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(proced_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e2fdbba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'êµ­ë¯¼ê³¼ ì†Œí†µí•˜ì‹œê³  ììœ ë¡­ê³  í–‰ë³µí•œ ë‚˜ë¼ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ í˜ì“°ê³  ê³„ì‹  ëŒ€í†µë ¹ê»˜ ì¡´ê²½ê³¼ ì°¬ì‚¬ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proced_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "757ea521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens (str)      : ['[CLS]', 'ë‚˜', '##ëŠ”', 'ì˜¤ëŠ˜', 'ì•„ì¹¨ë°¥', '##ì„', 'ë¨¹', '##ì—ˆ', '##ë‹¤', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer_torch = tokenizer(\"ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ë°¥ì„ ë¨¹ì—ˆë‹¤.\", return_tensors=\"pt\")\n",
    "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in tokenizer_torch['input_ids'].tolist()[0]]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72ebb13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] êµ­ë¯¼ê³¼ ì†Œí†µí•˜ì‹œê³  ììœ ë¡­ê³  í–‰ë³µí•œ ë‚˜ë¼ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ í˜ì“°ê³  ê³„ì‹  ëŒ€í†µë ¹ê»˜ ì¡´ê²½ê³¼ ì°¬ì‚¬ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤. [SEP]'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(proced_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "439be9c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] 3ë…„ì°¨ [MASK]ë²— [MASK] [MASK]ëŠ” ë” ì´ˆì‹¬ìœ¼ë¡œ ëŒì•„ê°€ ê°œí˜ í˜ì‹  [MASK] ì´ë£¨ [MASK] ì§€ì‹œê¸¸ ê¸°ë¶„ì¢‹ê²Œ ë§Œë“¤ì–´ ë³´ì‹œê¸¸ ì˜ ã… ~ ğŸ‘ğŸ˜ƒ [MASK] [SEP] ì €ëŠ” ë„ˆë¬´ í™©ë‹¹ [MASK] ê²ë„ ë‚˜ê³  [MASK]ì˜€ì§€ë§Œ í™”ê°€ë‚˜ì„œ ê·¸ ì°¨ ì˜†ì„ ì§€ë‚ ë•Œ í¬ë½ì…˜ [MASK] [MASK]ê³  ê°” [MASK] ì €ë¥¼ ë”°ë¼ì˜¨ ê·¸ [MASK] [MASK]ëŠ” ì œ ì˜†ì°¨ì„ ì— [MASK] ìš•ì„ í•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] [MASK] ê¸°ê°„ [MASK]ë£Œ [MASK] [MASK] 12ì›” 31ì¼ í‡´ê·¼ì§ì „ê¹Œì§€ë„ ëˆ„ê°€ ì‚´ì•„ë‚¨ê³  ëˆ„ê°€ ì§¤ë¦¬ëŠ”ì§€ [MASK] ëª¨ë¦…ë‹ˆë‹¤. [SEP] [MASK]. * * * ì†Œì¥ [MASK] 1 ) ê³„ì•½ì„œ [MASK] ì˜ì£¼ì§€ ì•ŠëŠ”ë‹¤ [MASK] [MASK]ì— ì‹¸ì¸ë§Œ ì´ê³³ì €ê³³ í•˜ê²Œë” í•˜ê³ ëŠ” íšŒì‚¬ì§ [MASK]ì„ ì°ê³  ë‚˜ì„œ ë‚˜ì¤‘ì— ë‹¤ì‹œ [MASK]ì— ì¤€ë‹¤ê³  ì´ì•¼ê¸° í•œë‹¤ [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] ì—°í‰ê·  [MASK] [MASK] 3 % ë¥¼ ë„˜ì§€ ëª»í•œ [MASK]. [SEP] ê·¸ë˜ì„œ ë§í•˜ëŠ” [MASK] ì¥ì• ì¸ [MASK] ê¸°ê°„ì„ 4ê°œì›” [MASK] ë³€ê²½í•´ì£¼ê³  ì˜ˆì „ì— [MASK]ë°›ì€ ì†Œê²¬ [MASK]ë‚˜ ë³‘ì›ì§„ë‹¨ì„œë„ ì ìš©ì´ ë˜ê²Œ í•´ì£¼ì„¸ìš” [MASK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] < ë¯¼ê°‘ë£¡ ê²½ì°°ì²­ [MASK] > [MASK]. [SEP] êµí†µì‚¬ê³  [MASK] [MASK]ê¸° ìœ„í•œ ë…¸ë ¥ì€ [MASK]ë˜ì–´ì•¼í•©ë‹ˆë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] ìš°ë¦¬ì• ë“¤ì´ ìˆëŠ”ë° ë£¸ì‹¸ [MASK] [MASK] ì™œê°‘ë‹ˆê¹Œ [MASK] ì¸í„°ë·° ê°„ ë‚˜ì˜¨ í•œ ìœ ëª… ê°ë…ì˜ [MASK]ì…ë‹ˆë‹¤. [SEP] [MASK] [MASK] ì§€ê¸ˆ ìš°ë¦¬ ëŒ€í•œ [MASK]ì˜ ì§€ë„ìë“¤ì˜ í˜„ìƒí™©ì…ë‹ˆë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "['[CLS] 3ë…„ì°¨ ì´ë²—ë…„ì—ëŠ” ë” ì´ˆì‹¬ìœ¼ë¡œ ëŒì•„ê°€ ê°œí˜ í˜ì‹ ì„ ì´ë£¨ì–´ ì§€ì‹œê¸¸ ê¸°ë¶„ì¢‹ê²Œ ë§Œë“¤ì–´ ë³´ì‹œê¸¸ ì˜ ã… ~ ğŸ‘ğŸ˜ƒ. [SEP] ì €ëŠ” ë„ˆë¬´ í™©ë‹¹í•˜ê³  ê²ë„ ë‚˜ê³  í•˜ì˜€ì§€ë§Œ í™”ê°€ë‚˜ì„œ ê·¸ ì°¨ ì˜†ì„ ì§€ë‚ ë•Œ í¬ë½ì…˜ì„ ìš¸ë¦¬ê³  ê°”ê³  ì €ë¥¼ ë”°ë¼ì˜¨ ê·¸ë‚¨ìëŠ” ì œ ì˜†ì°¨ì„ ì—ì„œ ìš•ì„ í•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] ì´ë ‡ê²Œ ê¸°ê°„ë§Œë£Œë‚ ì¸ 12ì›” 31ì¼ í‡´ê·¼ì§ì „ê¹Œì§€ë„ ëˆ„ê°€ ì‚´ì•„ë‚¨ê³  ëˆ„ê°€ ì§¤ë¦¬ëŠ”ì§€ ì „í˜€ ëª¨ë¦…ë‹ˆë‹¤. [SEP] 4. * * * ì†Œì¥ : 1 ) ê³„ì•½ì„œëŠ” ì˜ì£¼ì§€ ì•ŠëŠ”ë‹¤, ê³„ì•½ì„œì— ì‹¸ì¸ë§Œ ì´ê³³ì €ê³³ í•˜ê²Œë” í•˜ê³ ëŠ” íšŒì‚¬ì§ì¸ì„ ì°ê³  ë‚˜ì„œ ë‚˜ì¤‘ì— ë‹¤ì‹œ ê·¸ë•Œì— ì¤€ë‹¤ê³  ì´ì•¼ê¸° í•œë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] ì—°í‰ê·  ì„±ì¥ë¥ ì´ 3 % ë¥¼ ë„˜ì§€ ëª»í•œë‹¤. [SEP] ê·¸ë˜ì„œ ë§í•˜ëŠ”ë° ì¥ì• ì¸ì¦ ê¸°ê°„ì„ 4ê°œì›”ë¡œ ë³€ê²½í•´ì£¼ê³  ì˜ˆì „ì— ë°œê¸‰ë°›ì€ ì†Œê²¬ì„œë‚˜ ë³‘ì›ì§„ë‹¨ì„œë„ ì ìš©ì´ ë˜ê²Œ í•´ì£¼ì„¸ìš”.. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] < ë¯¼ê°‘ë£¡ ê²½ì°°ì²­ì¥ > ë„¤. [SEP] êµí†µì‚¬ê³ ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ë…¸ë ¥ì€ ê³„ì†ë˜ì–´ì•¼í•©ë‹ˆë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] ìš°ë¦¬ì• ë“¤ì´ ìˆëŠ”ë° ë£¸ì‹¸ë¡±ì„ ì™œê°‘ë‹ˆê¹Œ? ì¸í„°ë·° ê°„ ë‚˜ì˜¨ í•œ ìœ ëª… ê°ë…ì˜ ë°œì–¸ì…ë‹ˆë‹¤. [SEP] ì´ê²ƒì´ ì§€ê¸ˆ ìš°ë¦¬ ëŒ€í•œ ì²´ìœ¡ê³„ì˜ ì§€ë„ìë“¤ì˜ í˜„ìƒí™©ì…ë‹ˆë‹¤. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]])\n",
      "tensor([0, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = BERTLangaugeModelDataset(data=proced_data, tokenizer=tokenizer)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "\n",
    "for batch, (mlm_train, mlm_target, sent_emb, is_next) in enumerate(data_loader):\n",
    "#     print(mlm_train)\n",
    "    print(tokenizer.batch_decode(mlm_train))\n",
    "#     print(mlm_target)\n",
    "    print(tokenizer.batch_decode(mlm_target))\n",
    "    print(sent_emb)\n",
    "    print(is_next)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe67a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
